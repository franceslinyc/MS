\documentclass{beamer}
\usetheme{Boadilla}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color, colortbl}
\usepackage{caption}
\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\addbibresource{ref.bib}
\definecolor{cyan}{rgb}{.88,1,1}
\definecolor{gray}{gray}{.7}

\title{Comparison of Gaussian copula and random forests}
\subtitle{in zero-inflated spatial prediction}
\author{Nick Sun}
\institute{Oregon State University, Department of Statistics}
\date{\today}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Outline}
	\tableofcontents
\end{frame}

\section{Introduction}
\begin{frame}
\frametitle{Forestry Inventory}
\begin{itemize}
	\item Forestry inventory is a critical part of monitoring and servicing ecosystems and often involves statistical estimation of quantities such as total wood volume
	\item Since forests can cover enormous areas over rough terrain, it is often not possible to sample certain areas of forests due to physical, budgetary, or time constraints
	\item However, forestry data is often zero-inflated, heavily skewed, and spatially dependent, making it difficult to model using traditional statistical and geostatistical models
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Original Forestry Data}
	\begin{itemize}
		\item  The forestry inventory data used here was made available by the USDA Forestry Inventory and Analysis program, containing 13 variables of interest across 1224 plots of land in northwest Oregon.
	\end{itemize}
	\begin{center}
		\begin{figure}
		\includegraphics[width=.48\textwidth]{raw_histograms}
		\caption{Histograms of forestry inventory variables.}
		\end{figure}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Simulated Data}
	We simulated $m=1000$ datasets of size $n=1224$ for total timber volume and hemlock volume, two common variables of interest in forestry inventory applications.
	Previous work used a zero-inflated Gamma distribution to model these variables\cite{madsen09}.
	\begin{itemize}
		\item We create simulated datasets by generating multivariate normal observations with the sample correlation matrix from the original data
		\item We then backtransform using the quantile function of the zero-inflated gamma function that was found to fit the original data
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Resampled Data}
	\begin{itemize}
		\item We also generate training datasets by sampling rows without replacement from the orignal data with the remaining rows serving as a test set
		\item For models trained on these resampled datasets, we will be able to use covariates present in the Oregon dataset in our models, such as average annual precipitation
	\end{itemize}
	\begin{center}
		\begin{figure}[ht]
			\includegraphics[width=.6\textwidth]{timber_annpre}
			\caption{Alber's Equal Area Conic projection used here.}
		\end{figure}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{New Spatial Models}
	\begin{itemize}
		\item Two new techniques have been proposed to estimate spatially dependent data: spatial Gaussian copula and spatial random forests
		\item These simulations will compare the predictive performance of these new models and traditional kriging in different spatial prediction scenarios
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Kriging}
	\begin{itemize}
		\item In geostatistics, kriging is a method of spatial interpolation where values at unobserved locations are estimated using a weighted sum of known values
		\item In particular, if the data is normally distributed and satisfies \textit{second order stationarity}, \textit{i.e.} the covariances of points is a function only of the distance between the points and not the specific physical location of the points themselves, then kriging is the \textit{best linear unbiased estimator}\cite{cressie93}
	\end{itemize}
	\begin{align*}
		\hat{y}_{K}(s_0) = w(s_0)^T y
	\end{align*}
\end{frame}


%\begin{frame}
%	\frametitle{Kriging Primer}
%	Kriging is often thought of as a two-step process where:
%	\begin{enumerate}
%		\item Spatial covariance is determined by fitting a \textit{theoretical variogram} to the \textit{experimental variogram}
%		\item Observation weights are calculated using this covariance structure and used to interpolate or predict unobserved points
%	\end{enumerate}
%\end{frame}

%\begin{frame}
%	\frametitle{Kriging Primer}
%	\begin{itemize}
%	\item Often times, a theoretical variogram model is fit to the experimental variogram using interactive tools such as \texttt{geoR::eyefit}. 
%	\item For the purposes of this simulation study, the \texttt{automap} package will be used which relies on restricted maximum likelihood methods from the \texttt{gstat} package to fit the appropriate nugget and sill parameters, select the best theoretical model, and fit a kriging model.
%	\end{itemize}
%\end{frame}

\begin{frame}
	\frametitle{Spatial Gaussian Copula}
	\begin{itemize}
	\item Copulas are multivariate cumulative distribution functions where each variable has a standard uniform marginal distribution
	\item An important copula result:
	\end{itemize}
	\begin{theorem}[Sklar]
	Any $n$-dimensional multivarite cumulative distribution function $G(\vec{X})$ of a random vector $\vec{X} = (X_1, \ldots ,X_n)$ can be expressed in terms of the marginal cumulative distribution functions $F_i(X_i)$ and a copula function $C: [0,1]^n \rightarrow [0,1]$ such that
		\begin{align*}
			G(\vec{X}) = C(F_1(X_1), \ldots, F_n(X_n))
		\end{align*}
	\end{theorem}
\end{frame}


\begin{frame}
	\frametitle{New Spatial Models}
	\begin{itemize}
	\item Madsen\cite{madsen09} proposed a spatial Gaussian copula
	$$
	G(\vec{V}, \Sigma) = \Phi_{\Sigma}(\Phi^{-1}(F_1(v_1)), \ldots, \Phi^{-1}(F_n(v_n)))
	$$
	where the correlation matrix $\Sigma$ is chosen such that it represents the spatial relationships between each of the data points.
	\item Differentiating the above copula yield the joint density function of the spatially dependent data
	$$
	g(\vec{V}) = \| \Sigma \|^{1/2} \text{exp}\left(-\frac{1}{2} z^T (\Sigma^{-1} - I_n) z\right) \prod_{i = 1}^m f_i(y_i)
	$$
where $z = (\Phi^{-1}(F_1(y_1)), \ldots, \Phi^{-1}(F_n(y_n)))$.
	\item This copula will be able to incorporate the spatial dependency structure with the appropriate selection of $F$ and $\Sigma$.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Gaussian Copula}
	A common choice for spatial correlation matrix $\Sigma$ has $i,j$th entry equal to the value of the exponential correlogram function
	\begin{align*}
	\Sigma_{ij}(\theta) = 
		\begin{cases}
			\theta_0 \text{exp}(-h_{ij} \theta_1) & \text{ for } i \neq j\\
			1 & \text{ when } i = j
		\end{cases}
	\end{align*}
where $h_{ij}$ is the distance between the locations $y_i$ and $y_j$, $0 < \theta_0 \leq 1$ is the nugget parameter describing the variation of the data at $h = 0$, and $\theta_1 > 0$ is the decay parameter.
\end{frame}

\begin{frame}
	\frametitle{Marginal Distributions for Copula Model}
	An appropriate $F$ function would be one which can handle semicontinuous data.
	Previous work used a zero-inflated gamma function on cube-root transformed response data.
	\begin{align*}
	&f(x) = 
	\begin{cases}
		0 & \text{ w.p } p \\
		\frac{1}{\Gamma(\alpha) \beta^\alpha} x^{\alpha -1} \text{exp}\left(-\frac{x}{\beta}\right) & \text{ w.p. } 1 - p 
	\end{cases} 
	\\
	&\text{where } p \sim \text{Bernoulli}(\pi)
	\end{align*}
	\begin{itemize}
	\item The cube root transformation was used to make the continuous component less skewed
	\item Zero values were transformed to uniform random variables sampled from a $U(0, \epsilon)$ distribution where $\epsilon$ is the smallest nonzero value in the observed dataset
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Random Forests}
	\begin{itemize}
		\item The generic random forest is popular a machine learning algorithm which creates an ensemble of decision trees from the original data using \textit{bootstrap aggregation} and \textit{feature bagging}
		\item One of the notable advantages of using a machine learning algorithm like random forests is that no statistical assumptions are required
		\item Random forests have been used in spatial prediction, but the spatial information is often disregarded\cite{hengl18}.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Random Forests}
	\begin{itemize}
		\item The \textbf{RFsp} \texttt{R} package (built on top of \textbf{ranger}) introduces the spatial random forest:
		\begin{align*}
		Y(s) = f(X_G, X_R, X_P)
		\end{align*}
		where $X_G$ are covariates based on geographic proximity, and $X_R$ are surface reflectance covariates, and $X_P$ and process-based covariates
		\item Essentially, spatial dependence is modeled by training the random forest on distances from the training points
		\item Buffer distances between points was calculated in meters using \texttt{raster::pointDistances}
	\end{itemize}
\end{frame}

\section{Results}
\begin{frame}
	\frametitle{Model Comparisons}
	We will be comparing the predictive accuracy of the following models:
	\begin{enumerate}
		\item Spatial Gaussian copula with ZIG marginal distributions
		\item Ordinary kriging via \texttt{automap}
		\item Several spatial random forests with varying $num.trees = 50, 100, 150$
		\item \textit{Zero-corrected} kriging and spatial random forests where predicted values smaller than the smallest nonzero training observation are converted to 0
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Model Comparison Scenarios}
	We investigated three scenarios in our simulation:
	\begin{enumerate}
		\item Predicting simulated total volume with only spatial information
		\item Predicting simulated hemlock volume with only spatial information
		\item Predicting total volume with spatial information and annual precipitation using resampled data
	\end{enumerate}
	We will also examine how changes in the size of the training set affect the accuracy for different methods with $n = 100, 200, 300, 500, 1000, 1200$.
	\begin{itemize}
		\item Hemlock data was of particular study interest since nearly \textbf{56\%} of its original values were zeros, whereas total volume had \textbf{24.3\%} zeros.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Model Comparison Metrics}
	We used three prediction metrics to compare the performance of the models in each scenario:
	\begin{enumerate}
		\item Root Mean Squared Prediction Error (RMSPE)
		$$
		RMSPE = \sqrt{\frac{1}{mR} \sum_{r=1}^R \sum_{j=1}^m (\hat{y}_{j|r} - y_{j|r})^2}
		$$
		\item Signed Relative Bias (SRB)
		\item Prediction Interval Coverage ($PIC_{90}$)
	\end{enumerate}
	We will also examine residual plots and prediction performance for zero valued observations.
\end{frame}

%\begin{frame}
%	\frametitle{Metrics: RMSPE}
%		Our first prediction metric is root mean squared error
%		$$
%		RMSPE = \sqrt{\frac{1}{mR} \sum_{r=1}^R \sum_{j=1}^m (\hat{y}_{j|r} - y_{j|r})^2}
%		$$
%		where lower values are preferable to higher ones
%\end{frame}

\begin{frame}
	\frametitle{Metrics: Signed Relative Bias}
	\begin{align*}
		SRB &= \text{sign}(\tau) \sqrt{\frac{\tau^2}{MSPE - \tau^2}} \\
		\text{where }\tau &= \frac{1}{mR} \sum_{r = 1}^R \sum_{j = 1}^m (\hat{y}_{j|r} - y_{j|r})
	\end{align*}
	\begin{itemize}
		\item This formula derives from the fact that MSE is equal to the bias of the estimate squared plus the variance of the estimate
		\item A smaller absolute value of SRB indicates smaller bias in the method with a negative value indicating underprediction and a positive value indicating overprediction.\cite{verhoef13}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Metrics: 90\% Predictive Interval Coverage}
	\begin{align*}
		PIC_{90} = \frac{1}{mR} \sum_{r=1}^R \sum_{j=1}^m \text{I}\left(y_{j|r} \in \hat{y}_{j|r} \pm 1.645\hat{\text{se}}(\hat{y}_{j|r}) \right)
	\end{align*}
	where $\hat{\text{se}}(\hat{y}_{j|r})$ is the standard error of all the predicted values $\hat{y}_{j|r}$ in resampled dataset $r$.\cite{verhoef13}
	\begin{itemize}
		\item $PIC_{90}$ captures the proportion of actual values for the unobserved points fall within their respective 90\% prediction intervals.
		\item A well-calibrated model with proper assumptions should have a $PIC_{90}$ close to 90\%, but since our training and test points are spatially autocorrelated, we will examine this metric from the viewpoint of comparing models against one another. 
	\end{itemize}
\end{frame}

\subsubsection{RMSPE}
\begin{frame}
	\frametitle{RMSPE of Simulated Total Timber Volume}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & 246.139 & 238.878 & 251.040 & 250.719 & \cellcolor{gray}252.216 & 251.042 & \cellcolor{cyan}238.868 \\
		$1000$ & \cellcolor{gray}264.614 & 248.749 & 256.095 & 256.304 & 257.337 & 256.116 & \cellcolor{cyan}248.721 \\
		$500$ & 254.933 & 243.617 & 253.945 & 254.267 & \cellcolor{gray}255.217 & 253.957 & \cellcolor{cyan}243.604 \\
		$300$ & \cellcolor{gray}264.614 & 248.749 & 256.095 & 256.304 & 257.337 & 256.116 & \cellcolor{cyan}248.721 \\
		$200$ & \cellcolor{gray}275.154 & 253.674 & 258.074 & 258.246 & 259.417 & 258.113 & \cellcolor{cyan}253.628 \\
		$100$ & \cellcolor{gray}298.042 & 268.752 & \cellcolor{cyan}266.179 & 266.376 & 267.221 & 266.260 & 268.717 \\ [.5ex] 
		\hline
		\end{tabular}}
	\vspace{.06cm}

	\textit{Cyan indicates lowest RMSPE for sample size; gray indicates highest RMSPE.}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{RMSPE: Simulated Hemlock Volume}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Hemlock Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & 48.391 & 46.609 & 48.631 & 48.567 & \cellcolor{gray}48.799 & 48.632 & \cellcolor{cyan}46.594 \\
		$1000$ & \cellcolor{gray}50.500 & 48.318 & 50.197 & 50.268 & 50.442 & 50.197 & \cellcolor{cyan}48.309 \\
		$500$ & \cellcolor{gray}51.081 & 48.821 & 50.755 & 50.839 & 51.026 & 50.756 & \cellcolor{cyan}48.807 \\
		$300$ & \cellcolor{gray}51.456 & 49.879 & 51.040 & 51.120 & 51.332 & 51.041 & \cellcolor{cyan}49.866 \\
		$200$ & \cellcolor{gray}52.030 & 50.139 & 51.161 & 51.192 & 51.396 & 51.161 & \cellcolor{cyan}50.123 \\
		$100$ & \cellcolor{gray}52.542 & 51.560 & 51.671 & 51.679 & 51.911 & 51.671 & \cellcolor{cyan}51.546 \\ [.5ex] 
		\hline
		\end{tabular}}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{RMSPE: Resampled Total Volume}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Resampled Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & 296.905 & \cellcolor{gray}303.859 & \cellcolor{cyan}293.510 & 294.086 & 295.379 & \cellcolor{cyan}293.510 & 303.846 \\
		$1000$ & 295.311 & \cellcolor{gray}301.473 & \cellcolor{cyan}292.139 & 292.557 & 293.580 & \cellcolor{cyan}292.139 & 301.461 \\
		$500$ & 303.553 & \cellcolor{gray}304.366 & \cellcolor{cyan}296.997 & 297.362 & 298.388 & \cellcolor{cyan}296.997 & 304.349 \\
		$300$ & \cellcolor{gray}305.409 & 304.526 & \cellcolor{cyan}300.984 & 301.412 & 302.469 & \cellcolor{cyan}300.984 & 304.504 \\
		$200$ & \cellcolor{gray}308.267 & 304.898 & \cellcolor{cyan}303.921 & 304.393 & 305.360 & 303.922 & 304.867 \\
		$100$ & \cellcolor{gray}313.791 & 305.210 & \cellcolor{cyan}309.662 & 310.072 & 310.971 & 309.669 & 305.159 \\ [.5ex] 
		\hline
		\end{tabular}}
	\end{center}
\end{frame}

\subsubsection{SRB}

\begin{frame}
	\frametitle{SRB: Resampled Total Volume}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.146 & \cellcolor{cyan}-.001 & .003 & .003 & .003 & .003 & \cellcolor{cyan}-.001 \\
		$1000$ & \cellcolor{gray}-.155 & \cellcolor{cyan}.001 & .009 & .009 & .009 & .009 & \cellcolor{cyan}.001 \\
		$500$ & \cellcolor{gray}-.152 & \cellcolor{cyan}.001 & .007 & .007 & .006 & .006 & \cellcolor{cyan}.001 \\
		$300$ & \cellcolor{gray}-.161 & \cellcolor{cyan}.002 & .004 & .003 & .003 & .003 & \cellcolor{cyan}.002 \\
		$200$ & \cellcolor{gray}-.194 & \cellcolor{cyan}.000 & -.001 & -.001 & -.001 & -.002 & \cellcolor{cyan}.000 \\
		$100$ & \cellcolor{gray}-.134 & .006 & .003 & .003 & .003 & \cellcolor{cyan}.001 & .006 \\ [.5ex] 
		\hline
		\end{tabular}}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{SRB: Simulated Hemlock Volume}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Hemlock Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.184 & .014 & .012 & \cellcolor{cyan}.011 & \cellcolor{cyan}.011 & .012 & .015 \\
		$1000$ & \cellcolor{gray}-.190 & \cellcolor{cyan}.001 & .004 & .004 & .004 & .004 & .002 \\
		$500$ & \cellcolor{gray}-.190 & \cellcolor{cyan}.000 & .002 & .002 & .001 & .002 & .001 \\
		$300$ & \cellcolor{gray}-.190 & .003 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & .004 \\
		$200$ & \cellcolor{gray}-.189 & .002 & -.002 & \cellcolor{cyan}-.001 & \cellcolor{cyan}-.001 & -.002 & .003 \\
		$100$ & \cellcolor{gray}-.182 & .011 & \cellcolor{cyan}.002 & .003 & .003 & \cellcolor{cyan}.002 & .012 \\ [.5ex] 
		\hline
		\end{tabular}}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{SRB: Resampled Total Timber Data}
	\begin{center}
		\resizebox{\textwidth}{!}{%
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Resampled Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.300 & \cellcolor{cyan}-.002 & .012 & .012 & .014 & .012 & \cellcolor{cyan}-.002 \\
		$1000$ & \cellcolor{gray}-.297 & \cellcolor{cyan}.002 & .018 & .018 & .018 & .018 & \cellcolor{cyan}.002 \\
		$500$ & \cellcolor{gray}-.301 & \cellcolor{cyan}.000 & .013 & .013 & .013 & .013 & \cellcolor{cyan}.000 \\
		$300$ & \cellcolor{gray}-.292 & \cellcolor{cyan}.000 & .015 & .015 & .015 & .015 & .001 \\
		$200$ & \cellcolor{gray}-.282 & \cellcolor{cyan}.000 & .012 & .013 & .014 & .012 & \cellcolor{cyan}.000 \\
		$100$ & \cellcolor{gray}-.260 & \cellcolor{cyan}.007 & .008 & .008 & .009 & .008 & \cellcolor{cyan}.007 \\ [.5ex] 
		\hline
		\end{tabular}}
	\end{center}
\end{frame}

\subsubsection{Residual Plots}

%\begin{frame}
%	\frametitle{Residual Plots}
%	\begin{itemize}
%		\item We produced residual plots for the Gaussian copula, kriging, and random forests with $num.trees=150$ in each of the simulation scenarios with sample size $n = 500$
%		\item The dotted line on each plot corresponds indicates a predicted value of 0
%		\item We see that regardless of model or simulation method, $\hat{y}$ tended to underestimate large values of the observed response
%	\end{itemize}
%\end{frame}

\begin{frame}
	\frametitle{Total Volume Residual Plots}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=.5]{residual_plots}
		\caption{\label{fig:total_resids}Total volume residual plots}
	\end{figure}
	%\begin{itemize}
		%\item The residual plots in figure \ref{fig:total_resids} are similar for the most part.
		%\item There is a distinct line for the zero predicted values in the copula model whereas the kriging model predicted some negative values.
	%\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Hemlock Residual Plots}
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.5]{tshevol_residual_plots}
	\caption{\label{fig:hemlock_resids}Hemlock volume residual plots}
	\end{figure}
	%\begin{itemize}
	%\item Figure \ref{fig:hemlock_resids} suggests that random forests produce residuals with higher variance than either the other models.
	%\item While copula and kriging produced residual plots with almost rectangular shapes, random forests produced residuals that looked more like a cloud of points, particularly with observed values around 500.
	%\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Total Volume Residual Plots (Resampled)}
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.5]{resampling_residual_plots}
	\caption{\label{fig:resamp_resids}Resampled total volume residual plots}
	\end{figure}
	%\begin{itemize}
	%\item Figure \ref{fig:resamp_resids} shows that random forests have the widest residual spread which is relatively homoskedastic as observed values increase.
	%\item This contrasts with kriging residuals which appears as a narrowing funnel as observed values increases.
	%\item The kriging residuals also produced some predictions near zero, even for large values.
	%\end{itemize}
\end{frame}

\subsubsection{Prediction Interval Coverage}

\begin{frame}
	\frametitle{90\% Prediction Interval Coverage}
	\begin{center}
		\resizebox{\textwidth}{!}{%
	\begin{tabular}{|| c | c c c | c c c | c c c ||}
	\hline
	\multirow{2}{*}{} &
	\multicolumn{3}{c}{Total Volume} &
	\multicolumn{3}{c}{Hemlock} &
	\multicolumn{3}{c||}{Resampled} \\
	\hline
	$n$ & Copula & Kriging & $RFsp_{150}$ & Copula & Kriging & $RFsp_{150}$ & Copula & Kriging & $RFsp_{150}$ \\ [.5ex]
	\hline\hline
	$1200$ & .841 & \cellcolor{gray}.824 & \cellcolor{cyan}.846 & .721 &\cellcolor{gray}.569 &\cellcolor{cyan} .803 &.735 &\cellcolor{gray}.628 & \cellcolor{cyan}.795 \\
	$1000$ & .847 &\cellcolor{gray}.832 &\cellcolor{cyan} .855 &.718 &\cellcolor{gray}.595 &\cellcolor{cyan} .827 &.739 &\cellcolor{gray}.639 & \cellcolor{cyan}.801 \\
	$500$ & .835 &\cellcolor{gray}.814 &\cellcolor{cyan} .850 & .700 &\cellcolor{gray}.623 &\cellcolor{cyan} .819 &.717 &\cellcolor{gray}.629 & \cellcolor{cyan}.794 \\
	$300$ & .812 &\cellcolor{gray}.786 &\cellcolor{cyan} .844 & .689 &\cellcolor{gray}.640 &\cellcolor{cyan} .816 &.711 & \cellcolor{gray}.628 & \cellcolor{cyan}.785 \\
	$200$ & .793 &\cellcolor{gray}.759 &\cellcolor{cyan} .835 & .676 &\cellcolor{gray}.630 &\cellcolor{cyan} .803 &.706 &\cellcolor{gray}.633 & \cellcolor{cyan}.775 \\
	$100$ & .698 &\cellcolor{gray}.686 &\cellcolor{cyan} .809 & .630 &\cellcolor{gray}.590 &\cellcolor{cyan} .769 &.705 &\cellcolor{gray}.650 & \cellcolor{cyan}.751 \\ [.5ex] 
	\hline
	\end{tabular}}
	\end{center}
\end{frame}

\subsubsection{Prediction of zero values}

\begin{frame}
	\frametitle{Prediction of zero values}
	In the resampled data study with $n = 500$, we also calculated RMSPE and median predictions for points with an observed value of 0.
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.5]{zero_yhats}
	\caption{\label{fig:zero_yhats}Predictions for zero values}
	\end{figure}
	\begin{center}
		\resizebox{\textwidth}{!}{%
	\begin{tabular}{|| c | c | c | c | c | c ||}
	\hline
	\multicolumn{3}{||c|}{Median $\hat{y}$} &
	\multicolumn{3}{c||}{RMSPE} \\
	\hline
	Copula & $RFsp_{150}$(zeros) & Kriging(zeros)& Copula & $RFsp_{150}$(zeros) & Kriging(zeros)\\
	\hline
	\cellcolor{cyan}0 & 7.49 & \cellcolor{gray}40.5 & \cellcolor{cyan}20.7 & 59.6 & \cellcolor{gray}62.4 \\
	\hline
	\end{tabular}}
	\end{center}
\end{frame}

\section{Conclusion}
\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item The simulations in our study only covered a small subset of forestry inventory scenarios, but with the prediction metrics we selected, kriging matched or outperformed random forests and Gaussian copula by most measures.
	\item While both ordinary and universal kriging had a few data artifacts in the form of negative predictions, the kriging models consistently produced unbiased estimates with relatively low RMSPE.
	\item Both kriging and random forest models also had low absolute values of SRB, suggesting miniscule bias, if any. 
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item In contrast, our results suggest that the Gaussian copula model underpredicts values moreso than the other two techniques, which may be due to an overabundance of zeros in the predictions.
	\item Given the SRB metrics for each model, we might reasonably posit that model bias played a role in inflating the copula model's RMSPE.
	\item However, if properly estimating unobserved points which contain zero are of significant practical importance, the Gaussian copula far outperforms both random forest and kriging.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item For the semicontinuous, skewed responses we simulated, every single method underestimated large values, as evidenced by the downward trending residual plots we generated for each scenario.
	\item The residual plots also showed that the random forest predictions had greater variance than either the copula or the kriging.
	\item This larger variance also mainfests itself in the $PIC_{90}$ metrics where the random forest consistently had the greatest coverage among the methods.
	\end{itemize}
\end{frame}

\section{References}
\begin{frame}{References}
\printbibliography
\end{frame}

\end{document}
