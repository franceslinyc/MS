\documentclass{beamer}
\usetheme{Boadilla}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color, colortbl}
\usepackage{caption}
\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\addbibresource{ref.bib}
\definecolor{cyan}{rgb}{.88,1,1}
\definecolor{gray}{gray}{.7}

\title{Comparison of Gaussian copula and random forests}
\subtitle{in zero-inflated spatial prediction}
\author{Nick Sun}
\institute{Oregon State University, Department of Statistics}
\date{\today}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Outline}
	\tableofcontents
\end{frame}

\section{Introduction}
\begin{frame}
\frametitle{Forestry Inventory}
\begin{itemize}
	\item Forestry inventory is a critical part of monitoring and servicing ecosystems and often involves statistical estimation of quantities such as total wood volume.
	\item Since forests can cover enormous areas over rough terrain, it is often not possible to sample certain areas of forests due to physical, budgetary, or time constraints.
	\item However, forestry data is often zero-inflated, heavily skewed, and spatially dependent, making it difficult to model using traditional statistical and geostatistical models.
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Forestry Data}
	\begin{itemize}
		\item  The forestry inventory data used here was made available by the Forestry Inventory and Analysis program of the USDA Forest Service, containing inventory information on 13 variables of interest across 1224 plots of land in northwest Oregon.
	\end{itemize}
	\begin{center}
		\begin{figure}
		\includegraphics[width=.48\textwidth]{raw_histograms}
		\caption{Histograms of forestry inventory variables.}
		\end{figure}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Simulated Data}
	\begin{itemize}
		\item We create simulated datasets by generating multivariate normal observations with the sample correlation matrix from the original data.
		\item We then backtransform using the quantile function of the zero-inflated gamma function that was found to fit the original data.
		\item We simulated $m=1000$ datasets of size $n=1224$ for total timber volume and hemlock volume, two common variables of interest in forestry inventory applications.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Resampled Data}
	\begin{itemize}
		\item We also generate training datasets by sampling rows without replacement from the orignal data with the remaining rows serving as a test set.
		\item For models trained on these resampled datasets, we will be able to use covariates present in the Oregon dataset in our models, such as annual average temperature and precipitation.
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Annual Precipitation and Total Timber Volume}
	\begin{center}
		\begin{figure}[ht]
			\includegraphics[width=\textwidth]{timber_annpre}
			\caption{Alber's Equal Area Conic projection used here.}
		\end{figure}
	\end{center}
\end{frame}

\section{Methods}

\begin{frame}
	\frametitle{New Spatial Models}
	\begin{itemize}
		\item  These simulations will compare the predictive performance of spatial Gaussian copula, spatial random forest, and kriging in different scenarios and sample sizes.
		\item Two new techniques have been proposed to estimate spatially dependent data: spatial Gaussian copula and spatial random forests.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Kriging Primer}
	\begin{itemize}
		\item In geostatistics, kriging is a method of spatial interpolation where values at unobserved locations are estimated using a weighted sum of known values.
		\item In particular, if the data is normally distributed and satisfies \textit{second order stationarity}, this is, if the covariances of points is a function only of the distance between the points and not the specific physical location of the points themselves, then kriging is the \textit{best linear unbiased estimator}\cite{cressie93}.
	\end{itemize}
	\begin{align*}
		\hat{y}_{K}(s_0) = w(s_0)^T y
	\end{align*}
\end{frame}


\begin{frame}
	\frametitle{Kriging Primer}
	Kriging is often thought of as a two-step process where:
	\begin{enumerate}
		\item Spatial covariance is determined by fitting a \textit{theoretical variogram} to the \textit{experimental variogram}
		\item Observation weights are calculated using this covariance structure and used to interpolate or predict unobserved points
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Kriging Primer}
	\begin{itemize}
	\item Often times, a theoretical variogram model is fit to the experimental variogram using interactive tools such as \texttt{geoR::eyefit}. 
	\item For the purposes of this simulation study, the \texttt{automap} package will be used which relies on restricted maximum likelihood methods from the \texttt{gstat} package to fit the appropriate nugget and sill parameters, select the best theoretical model, and fit a kriging model.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Gaussian Copula}
	\begin{itemize}
	\item Copulas are multivariate cumulative distribution functions where each variable has a standard uniform marginal distribution.
	\item An important copula result is Sklar's Theorem:
	\end{itemize}
	\begin{theorem}	
	Any $n$-dimensional multivarite cumulative distribution function $G(\vec{X})$ of a random vector $\vec{X} = (X_1, \ldots ,X_n)$ can be expressed in terms of the marginal cumulative distribution functions $F_i(X_i)$ and a copula function $C: [0,1]^n \rightarrow [0,1]$ such that
		\begin{align*}
			G(\vec{X}) = C(F_1(X_1), \ldots, F_n(X_n))
		\end{align*}
	\end{theorem}
\end{frame}


\begin{frame}
	\frametitle{New Spatial Models}
	\begin{itemize}
	\item Madsen\cite{madsen09} proposed a spatial Gaussian copula
	$$
	G(\vec{V}, \Sigma) = \Phi_{\Sigma}(\Phi^{-1}(F_1(v_1)), \ldots, \Phi^{-1}(F_n(v_n)))
	$$
	where the correlation matrix $\Sigma$ is chosen such that it represents the spatial relationships between each of the data points.
	\item Differentiating the above copula yield the joint density function of the spatially dependent data
	$$
	g(\vec{V}) = \| \Sigma \|^{1/2} \text{exp}\left(-\frac{1}{2} z^T (\Sigma^{-1} - I_n) z\right) \prod_{i = 1}^m f_i(y_i)
	$$
where $z = (\Phi^{-1}(F_1(y_1)), \ldots, \Phi^{-1}(F_n(y_n)))$.
	\item This copula will be able to incorporate the spatial dependency structure, however this method requires the appropriate selection of $F$ and $\Sigma$.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Gaussian Copula}
	A common choice for spatial correlation matrix $\Sigma$ has $i,j$th entry equal to the value of the exponential correlogram function
	\begin{align*}
	\Sigma_{ij}(\theta) = 
		\begin{cases}
			\theta_0 \text{exp}(-h_{ij} \theta_1) & \text{ for } i \neq j\\
			1 & \text{ when } i = j
		\end{cases}
	\end{align*}
where $h_{ij}$ is the distance between the locations $y_i$ and $y_j$, $0 < \theta_0 \leq 1$ is the nugget parameter describing the variation of the data at $h = 0$, and $\theta_1 > 0$ is the decay parameter.
\end{frame}

\begin{frame}
	\frametitle{Marginal Distributions for Copula Model}
	An appropriate $F$ function would be one which can handle semicontinuous data.
	We have chosen to use a zero-inflated gamma function on cube-root transformed response data.
	\begin{align*}
	&f(x) = 
	\begin{cases}
		0 & \text{ w.p } p \\
		\frac{1}{\Gamma(\alpha) \beta^\alpha} x^{\alpha -1} \text{exp}\left(-\frac{x}{\beta}\right) & \text{ w.p. } 1 - p 
	\end{cases} 
	\\
	&\text{where } p \sim \text{Bernoulli}(\pi)
	\end{align*}
	\begin{itemize}
	\item The cube root transformation was necessary to make the continuous component less heavily skewed.
	\item Additionally, for the purposes of the copula model, zero values were instead replaced with uniform random variables sampled from a $U(0, \epsilon)$ distribution where $\epsilon$ is the smallest nonzero value in the observed dataset.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Random Forests}
	\begin{itemize}
		\item The random forest is a machine learning algorithm which creates an ensemble of weak decision tree learners from bootstrapped (also referred to as \textit{bagged}) samples of the original data\cite{breiman01}.
		\item Random forest have been used in spatial prediction, but the spatial information is often disregarded\cite{hengl18}.
		\item One of the notable advantages of using a machine learning algorithm like random forests is that no statistical assumptions are required, therefore, we are not required to transform the shape of the data as we had to in the Gaussian copula model.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Spatial Random Forests}
	\begin{itemize}
		\item In order to incorporate this information in the model, the \textbf{RFsp} packages introduces the spatial random forest which uses buffer distances from observed points as explanatory variables.
		\item The generic spatial random forest system is proposed in terms of three main input components:
		\begin{align*}
		Y(s) = f(X_G, X_R, X_P)
		\end{align*}
		where $X_G$ are covariates based on geographic proximity or spatial relationships, and $X_R$ and $X_P$ are referred to respectively as surface reflectance covariates and process-based covariates.
	\end{itemize}
\end{frame}

\section{Results}
\begin{frame}
	\frametitle{Model Comparisons}
	We will be comparing the predictive accuracy of the following models:
	\begin{enumerate}
		\item Spatial Gaussian copula with ZIG marginal distributions
		\item Ordinary kriging via \texttt{automap}
		\item Several spatial random forests with varying $n.trees = 50, 100, 150$
		\item Semicontinuous corrected kriging and spatial random forests where predicted values smaller than the smallest nonzero training observation are converted to 0
	\end{enumerate}
	\begin{itemize}
		\item Testing will be done on simulated total volume and hemlock volume, as well as the resampled original data.
		\item Hemlock data was of particular study interest since nearly \textbf{56\%} of its original values were zeros, possibly representing a more significant challenge to model than total volume which had \textbf{24.3\%} zeros.
		\item We will also examine how changes in the size of the training set affect the accuracy for different methods with $n = 100, 200, 300, 500, 1000, 1200$.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Metrics: RMSPE}
		Our first prediction metric is root mean squared error
		$$
		RMSPE = \sqrt{\frac{1}{mR} \sum_{r=1}^R \sum_{j=1}^m (\hat{y}_{j|r} - y_{j|r})^2}
		$$
		where lower values are preferable to higher ones
\end{frame}

\begin{frame}
	\frametitle{Metrics: Signed Relative Bias}
	\begin{align*}
	SRB = \text{sign}(\tau) \sqrt{\frac{\tau^2}{MSPE - \tau^2}}
	\end{align*}
	where $\tau = \frac{1}{mR} \sum_{r = 1}^R \sum_{j = 1}^m (\hat{y}_{j|r} - y_{j|r})$.
	\begin{itemize}
		\item This formula derives from the fact that mean squared prediction error is equal to the bias of the estimate squared plus the variance of the estimate.
		\item A smaller absolute value of SRB indicates smaller bias in the method with a negative value indicating underprediction and a positive value indicating overprediction.\cite{verhoef13}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Metrics: 90\% Predictive Interval Coverage}
	\begin{align*}
	PIC_{90} = \frac{1}{mR} \sum_{r=1}^R \sum_{j=1}^m I\left(\hat{y}_{j|r} - 1.645\hat{\text{se}}(\hat{y}_{j|r}) \geq y_{j|r} \cap y_{j|r} \leq \hat{y}_{j|r} + 1.645\hat{\text{se}}(\hat{y}_{j|r})\right)
	\end{align*}
	where $\hat{\text{se}}(\hat{y}_{j|r})$ is the standard error of all the predicted values $\hat{y}_{j|r}$ in resampled dataset $r$.\cite{verhoef13}
	\begin{itemize}
		\item $PIC_{90}$ captures the proportion of actual values for the unobserved points fall within their respective 90\% prediction intervals.
		\item A well-calibrated model with proper assumptions should have a $PIC_{90}$ close to 90\%, but since our training and test points are spatially autocorrelated, we will examine this metric from the viewpoint of comparing models against one another. 
	\end{itemize}
\end{frame}

\subsubsection{RMSPE}
\begin{frame}
	\frametitle{RMSPE of Simulated Total Timber Volume}
	\begin{center}
	\begin{tabular}{|| c | c c c c c c c ||}
	\hline
	\multicolumn{8}{||c||}{Simulated Total Volume} \\
	\hline
	$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
	\hline\hline
	$1200$ & 246.139 & 238.878 & 251.040 & 250.719 & \cellcolor{gray}252.216 & 251.042 & \cellcolor{cyan}238.868 \\
	$1000$ & \cellcolor{gray}264.614 & 248.749 & 256.095 & 256.304 & 257.337 & 256.116 & \cellcolor{cyan}248.721 \\
	$500$ & 254.933 & 243.617 & 253.945 & 254.267 & \cellcolor{gray}255.217 & 253.957 & \cellcolor{cyan}243.604 \\
	$300$ & \cellcolor{gray}264.614 & 248.749 & 256.095 & 256.304 & 257.337 & 256.116 & \cellcolor{cyan}248.721 \\
	$200$ & \cellcolor{gray}275.154 & 253.674 & 258.074 & 258.246 & 259.417 & 258.113 & \cellcolor{cyan}253.628 \\
	$100$ & \cellcolor{gray}298.042 & 268.752 & \cellcolor{cyan}266.179 & 266.376 & 267.221 & 266.260 & 268.717 \\ [.5ex] 
	\hline
	\end{tabular}
	\vspace{.06cm}

	\textit{Cyan indicates lowest RMSPE for sample size; gray indicates highest RMSPE.}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{RMSPE: Simulated Hemlock Volume}
	\begin{center}
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Hemlock Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & 48.391 & 46.609 & 48.631 & 48.567 & \cellcolor{gray}48.799 & 48.632 & \cellcolor{cyan}46.594 \\
		$1000$ & \cellcolor{gray}50.500 & 48.318 & 50.197 & 50.268 & 50.442 & 50.197 & \cellcolor{cyan}48.309 \\
		$500$ & \cellcolor{gray}51.081 & 48.821 & 50.755 & 50.839 & 51.026 & 50.756 & \cellcolor{cyan}48.807 \\
		$300$ & \cellcolor{gray}51.456 & 49.879 & 51.040 & 51.120 & 51.332 & 51.041 & \cellcolor{cyan}49.866 \\
		$200$ & \cellcolor{gray}52.030 & 50.139 & 51.161 & 51.192 & 51.396 & 51.161 & \cellcolor{cyan}50.123 \\
		$100$ & \cellcolor{gray}52.542 & 51.560 & 51.671 & 51.679 & 51.911 & 51.671 & \cellcolor{cyan}51.546 \\ [.5ex] 
		\hline
		\end{tabular}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{RMSPE: Resampled Total Volume}
	\begin{center}
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Resampled Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & 296.905 & \cellcolor{gray}303.859 & \cellcolor{cyan}293.510 & 294.086 & 295.379 & \cellcolor{cyan}293.510 & 303.846 \\
		$1000$ & 295.311 & \cellcolor{gray}301.473 & \cellcolor{cyan}292.139 & 292.557 & 293.580 & \cellcolor{cyan}292.139 & 301.461 \\
		$500$ & 303.553 & \cellcolor{gray}304.366 & \cellcolor{cyan}296.997 & 297.362 & 298.388 & \cellcolor{cyan}296.997 & 304.349 \\
		$300$ & \cellcolor{gray}305.409 & 304.526 & \cellcolor{cyan}300.984 & 301.412 & 302.469 & \cellcolor{cyan}300.984 & 304.504 \\
		$200$ & \cellcolor{gray}308.267 & 304.898 & \cellcolor{cyan}303.921 & 304.393 & 305.360 & 303.922 & 304.867 \\
		$100$ & \cellcolor{gray}313.791 & 305.210 & \cellcolor{cyan}309.662 & 310.072 & 310.971 & 309.669 & 305.159 \\ [.5ex] 
		\hline
		\end{tabular}
	\end{center}
\end{frame}

\subsubsection{SRB}

\begin{frame}
	\frametitle{SRB: Resampled Total Volume}
	\begin{center}
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.146 & \cellcolor{cyan}-.001 & .003 & .003 & .003 & .003 & \cellcolor{cyan}-.001 \\
		$1000$ & \cellcolor{gray}-.155 & \cellcolor{cyan}.001 & .009 & .009 & .009 & .009 & \cellcolor{cyan}.001 \\
		$500$ & \cellcolor{gray}-.152 & \cellcolor{cyan}.001 & .007 & .007 & .006 & .006 & \cellcolor{cyan}.001 \\
		$300$ & \cellcolor{gray}-.161 & \cellcolor{cyan}.002 & .004 & .003 & .003 & .003 & \cellcolor{cyan}.002 \\
		$200$ & \cellcolor{gray}-.194 & \cellcolor{cyan}.000 & -.001 & -.001 & -.001 & -.002 & \cellcolor{cyan}.000 \\
		$100$ & \cellcolor{gray}-.134 & .006 & .003 & .003 & .003 & \cellcolor{cyan}.001 & .006 \\ [.5ex] 
		\hline
		\end{tabular}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{SRB: Simulated Hemlock Volume}
	\begin{center}
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Simulated Hemlock Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.184 & .014 & .012 & \cellcolor{cyan}.011 & \cellcolor{cyan}.011 & .012 & .015 \\
		$1000$ & \cellcolor{gray}-.190 & \cellcolor{cyan}.001 & .004 & .004 & .004 & .004 & .002 \\
		$500$ & \cellcolor{gray}-.190 & \cellcolor{cyan}.000 & .002 & .002 & .001 & .002 & .001 \\
		$300$ & \cellcolor{gray}-.190 & .003 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & \cellcolor{cyan}.001 & .004 \\
		$200$ & \cellcolor{gray}-.189 & .002 & -.002 & \cellcolor{cyan}-.001 & \cellcolor{cyan}-.001 & -.002 & .003 \\
		$100$ & \cellcolor{gray}-.182 & .011 & \cellcolor{cyan}.002 & .003 & .003 & \cellcolor{cyan}.002 & .012 \\ [.5ex] 
		\hline
		\end{tabular}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{SRB: Resampled Total Timber Data}
	\begin{center}
		\begin{tabular}{|| c | c c c c c c c ||}
		\hline
		\multicolumn{8}{||c||}{Resampled Total Volume} \\
		\hline
		$n$ & Copula & Kriging & $RFsp_{150}$ & $RFsp_{100}$ & $RFsp_{50}$ & $RFsp_{150}(zeros)$ & Kriging (zeros) \\ [.5ex] 
		\hline\hline
		$1200$ & \cellcolor{gray}-.300 & \cellcolor{cyan}-.002 & .012 & .012 & .014 & .012 & \cellcolor{cyan}-.002 \\
		$1000$ & \cellcolor{gray}-.297 & \cellcolor{cyan}.002 & .018 & .018 & .018 & .018 & \cellcolor{cyan}.002 \\
		$500$ & \cellcolor{gray}-.301 & \cellcolor{cyan}.000 & .013 & .013 & .013 & .013 & \cellcolor{cyan}.000 \\
		$300$ & \cellcolor{gray}-.292 & \cellcolor{cyan}.000 & .015 & .015 & .015 & .015 & .001 \\
		$200$ & \cellcolor{gray}-.282 & \cellcolor{cyan}.000 & .012 & .013 & .014 & .012 & \cellcolor{cyan}.000 \\
		$100$ & \cellcolor{gray}-.260 & \cellcolor{cyan}.007 & .008 & .008 & .009 & .008 & \cellcolor{cyan}.007 \\ [.5ex] 
		\hline
		\end{tabular}
	\end{center}
\end{frame}

\subsubsection{Residual Plots}

\begin{frame}
	\frametitle{Residual Plots}
	\begin{itemize}
		\item We produced residual plots for the Gaussian copula, kriging, and random forests with $num.trees=150$ in each of the simulation scenarios with sample size $n = 500$.
		\item The dotted line on each plot corresponds indicates a predicted value of 0.
		\item We see that regardless of model or simulation method, $\hat{y}$ tended to underestimate large values of the observed response.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Residual Plots}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=.7]{residual_plots}
		\caption{\label{fig:total_resids}Total volume residual plots}
	\end{figure}
	\begin{itemize}
		\item The residual plots in figure \ref{fig:total_resids} are similar for the most part.
		\item There is a distinct line for the zero predicted values in the copula model whereas the kriging model predicted some negative values.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{New Spatial Models}
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.7]{tshevol_residual_plots}
	\caption{\label{fig:hemlock_resids}Hemlock volume residual plots}
	\end{figure}
	\begin{itemize}
	\item Figure \ref{fig:hemlock_resids} suggests that random forests produce residuals with higher variance than either the other models.
	\item While copula and kriging produced residual plots with almost rectangular shapes, random forests produced residuals that looked more like a cloud of points, particularly with observed values around 500.
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{New Spatial Models}
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.7]{resampling_residual_plots}
	\caption{\label{fig:resamp_resids}Resampled total volume residual plots}
	\end{figure}
	\begin{itemize}
	\item Figure \ref{fig:resamp_resids} shows that random forests have the widest residual spread which is relatively homoskedastic as observed values increase.
	\item This contrasts with kriging residuals which appears as a narrowing funnel as observed values increases.
	\item The kriging residuals also produced some predictions near zero, even for large values.
	\end{itemize}
\end{frame}

\subsubsection{Prediction Interval Coverage}

\begin{frame}
	\frametitle{90\% Prediction Interval Coverage}
	\begin{center}
		\resizebox{\textwidth}{!}{%
	\begin{tabular}{|| c | c c c | c c c | c c c ||}
	\hline
	\multirow{2}{*}{} &
	\multicolumn{3}{c}{Total Volume} &
	\multicolumn{3}{c}{Hemlock} &
	\multicolumn{3}{c||}{Resampled} \\
	\hline
	$n$ & Copula & Kriging & $RFsp_{150}$ & Copula & Kriging & $RFsp_{150}$ & Copula & Kriging & $RFsp_{150}$ \\ [.5ex]
	\hline\hline
	$1200$ & .841 & \cellcolor{gray}.824 & \cellcolor{cyan}.846 & .721 &\cellcolor{gray}.569 &\cellcolor{cyan} .803 &.735 &\cellcolor{gray}.628 & \cellcolor{cyan}.795 \\
	$1000$ & .847 &\cellcolor{gray}.832 &\cellcolor{cyan} .855 &.718 &\cellcolor{gray}.595 &\cellcolor{cyan} .827 &.739 &\cellcolor{gray}.639 & \cellcolor{cyan}.801 \\
	$500$ & .835 &\cellcolor{gray}.814 &\cellcolor{cyan} .850 & .700 &\cellcolor{gray}.623 &\cellcolor{cyan} .819 &.717 &\cellcolor{gray}.629 & \cellcolor{cyan}.794 \\
	$300$ & .812 &\cellcolor{gray}.786 &\cellcolor{cyan} .844 & .689 &\cellcolor{gray}.640 &\cellcolor{cyan} .816 &.711 & \cellcolor{gray}.628 & \cellcolor{cyan}.785 \\
	$200$ & .793 &\cellcolor{gray}.759 &\cellcolor{cyan} .835 & .676 &\cellcolor{gray}.630 &\cellcolor{cyan} .803 &.706 &\cellcolor{gray}.633 & \cellcolor{cyan}.775 \\
	$100$ & .698 &\cellcolor{gray}.686 &\cellcolor{cyan} .809 & .630 &\cellcolor{gray}.590 &\cellcolor{cyan} .769 &.705 &\cellcolor{gray}.650 & \cellcolor{cyan}.751 \\ [.5ex] 
	\hline
	\end{tabular}}
	\end{center}
\end{frame}

\subsubsection{Prediction of zero values}

\begin{frame}
	\frametitle{Prediction of zero values}
	In the resampled data study with $n = 500$, we also calculated RMSPE and median predictions among the different methods for points with an observed value of 0.
	\begin{figure}[h]
		\centering
	\includegraphics[scale=.7]{zero_yhats}
	\caption{\label{fig:zero_yhats}Predictions for zero values}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{Prediction of zero values}
	Figure \ref{fig:zero_yhats} displays the histograms of the predicted values for the Gaussian copula, zero-corrected random forest, and zero-corrected universal kriging. 
		\begin{center}
		\begin{tabular}{|| c | c | c | c | c | c ||}
		\hline
		\multicolumn{3}{||c|}{Median $\hat{y}$} &
		\multicolumn{3}{c||}{RMSPE} \\
		\hline
		Copula & $RFsp_{150}$(zeros) & Kriging(zeros)& Copula & $RFsp_{150}$(zeros) & Kriging(zeros)\\
		\hline
		\cellcolor{cyan}0 & 61.3 & \cellcolor{gray}131 & \cellcolor{cyan}115 & 170 & \cellcolor{gray}201 \\
		\hline
		\end{tabular}
		\end{center}
\end{frame}

\section{Conclusion}
\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item The simulations in our study only covered a small subset of forestry inventory scenarios, but with the prediction metrics we selected, kriging matched or outperformed random forests and Gaussian copula by most measures.
	\item While both ordinary and universal kriging had a few data artifacts in the form of negative predictions, the kriging models consistently produced unbiased estimates with relatively low RMSPE.
	\item Both kriging and random forest models also had low absolute values of SRB, suggesting miniscule bias, if any. 
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item In contrast, our results suggest that the Gaussian copula model underpredicts values moreso than the other two techniques, which may be due to an overabundance of zeros in the predictions.
	\item Given the SRB metrics for each model, we might reasonably posit that model bias played a role in inflating the copula model's RMSPE.
	\item However, if properly estimating unobserved points which contain zero are of significant practical importance, the Gaussian copula far outperforms both random forest and kriging.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Conclusion}
	\begin{itemize}
	\item For the semicontinuous, skewed responses we simulated, every single method underestimated large values, as evidenced by the downward trending residual plots we generated for each scenario.
	\item The residual plots also showed that the random forest predictions had greater variance than either the copula or the kriging.
	\item This larger variance also mainfests itself in the $PIC_{90}$ metrics where the random forest consistently had the greatest coverage among the methods.
	\end{itemize}
\end{frame}

\section{References}
\begin{frame}{References}
\printbibliography
\end{frame}

\end{document}
